import os
import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

# ====== SETTINGS ======
UPLOAD_PASSWORD = "upload123"   # üîí password to restrict uploads
VECTOR_DB_PATH = "faiss_index"

# ====== INITIALIZATION ======
st.set_page_config(page_title="Secure Chatbot", layout="wide")
st.title("üîí Secure Chatbot (FAISS + OpenAI API)")

# Load OpenAI API key from environment
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("‚ùå Missing OpenAI API key. Please set the environment variable `OPENAI_API_KEY`.")
    st.stop()

embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model="gpt-4o-mini", temperature=0)

# ====== LOAD OR CREATE VECTOR DB ======
if os.path.exists(VECTOR_DB_PATH):
    vectorstore = FAISS.load_local(VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
else:
    vectorstore = None

memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

if vectorstore:
    retriever = vectorstore.as_retriever()
    qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever, memory=memory)
else:
    qa_chain = None

# ====== FILE UPLOAD (restricted) ======
st.subheader("üìÇ Upload Documents (Restricted)")
upload_password = st.text_input("Enter upload password:", type="password")

if upload_password == UPLOAD_PASSWORD:
    uploaded_files = st.file_uploader("Upload PDF documents", type="pdf", accept_multiple_files=True)
    if uploaded_files:
        all_texts = []
        for uploaded_file in uploaded_files:
            pdf = PdfReader(uploaded_file)
            text = "".join([page.extract_text() or "" for page in pdf.pages])
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            all_texts.extend(splitter.split_text(text))

        if all_texts:
            vectorstore = FAISS.from_texts(all_texts, embedding=embeddings)
            vectorstore.save_local(VECTOR_DB_PATH)
            retriever = vectorstore.as_retriever()
            qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever, memory=memory)
            st.success("‚úÖ Documents uploaded & FAISS index updated.")
else:
    st.info("‚ÑπÔ∏è Upload restricted. Only chatting is allowed without password.")

# ====== CHAT INTERFACE (open to everyone) ======
st.subheader("üí¨ Chat with your documents")
if qa_chain:
    user_question = st.text_input("Ask a question:")
    if user_question:
        with st.spinner("Thinking..."):
            response = qa_chain.invoke({"question": user_question})
            st.write("ü§ñ:", response["answer"])
else:
    st.warning("‚ö†Ô∏è Please upload documents first (requires password).")
