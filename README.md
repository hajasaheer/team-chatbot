
 ## ğŸ“š Team Knowledge AI Chatbot

An AI-powered chatbot that lets your team **upload documents** and query them in natural language.
Built with **Streamlit**, **Qdrant**, **Sentence Transformers**, and **Ollama** (local LLM).



## ğŸš€ Features

* Upload and manage team documents (PDF, TXT, DOCX, CSV, MD).
* Ask questions and get answers with context from your documents.
* Answers are streamed from a local LLM (via Ollama).
* Smart caching:

  * **Exact cache** â†’ instant repeat answers.
  * **Semantic cache** â†’ reuse similar past answers.
* Admin panel with document stats and cache management.



 ## ğŸ› ï¸ Prerequisites

* Python **3.9+**
* `pip` installed
* **Ollama** running locally (`ollama run llama3` to verify)
* **Qdrant** running locally (via Docker):

```bash
docker run -d -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant
```

---

 ## ğŸ“¦ Installation

```bash
# Clone the repo
git clone https://github.com/hajasaheer/team-chatbot.git
cd team-chatbot

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## âš™ï¸ Configuration

Create a `.env` file in the project root:

```env
# Qdrant settings
QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY=   # optional if secured

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")

# Collections
DOC_COLLECTION = os.getenv("DOC_COLLECTION", "documents")
CACHE_COLLECTION = os.getenv("CACHE_COLLECTION", "chat_cache")

# Models
DEFAULT_MODEL=llama3
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Semantic cache
SEMANTIC_CACHE_MIN_SCORE=0.5
```

---

## ğŸ“‚ Project Structure

```
team-bot/
â”‚â”€â”€ venv/                # Python virtual environment
â”‚â”€â”€ app.py                # Streamlit entrypoint
â”‚â”€â”€ pages/
â”‚   â”œâ”€â”€ Chatbot.py        # Chat interface
â”‚   â””â”€â”€ Admin.py          # Document ingestion & cache management
â”‚â”€â”€ utils/
â”‚   â”œâ”€â”€ qa.py             # Qdrant, embeddings, caching, Ollama logic
â”‚   â”œâ”€â”€ ingestion.py      # PDF/text extraction, chunking, embedding
â”‚   â””â”€â”€ ollama_client.py  # (optional Ollama helpers)
â”‚â”€â”€ .env                  # Configuration
```

---

## â–¶ï¸ Running the Application

Start Streamlit manually:

```bash
streamlit run app.py --server.port=8501 --server.address=0.0.0.0
```

Or set up as a **systemd service**:

```ini
[Unit]
Description=Team Bot - Streamlit LangChain Chatbot
After=network.target

[Service]
User=root
WorkingDirectory=/root/team-bot
ExecStart=/root/team-bot/venv/bin/streamlit run /root/team-bot/app.py --server.port=8501 --server.address=0.0.0.0
Restart=always
RestartSec=10
Environment="PYTHONUNBUFFERED=1"

[Install]
WantedBy=multi-user.target
```

Then open: [http://localhost:8501](http://localhost:8501)

---

## ğŸ’¡ Usage

### Main Menu

* Navigate between **Chat** and **Admin** pages.

### Chatbot Page

1. Enter a question.
2. Bot will:

   * Check cache for past answers.
   * Retrieve context from Qdrant.
   * Build a prompt.
   * Stream an answer from Ollama.
   * Cache the result.

### Admin Page

* Upload new documents for ingestion.
* View Qdrant debug info & collection stats.
* Clear or delete cache entries.

---

## âš™ï¸ How It Works

1. **Document Ingestion**

   * PDFs parsed with PyPDF2.
   * Text chunked (500 chars, 50 overlap).
   * Chunks embedded with SentenceTransformers.
   * Stored in Qdrant with metadata.

2. **Question Answering**

   * Query â†’ embedded and searched in Qdrant.
   * Top matches â†’ context for the LLM.
   * Prompt sent to Ollama model.
   * Answer streamed back and cached.

3. **Cache**

   * **Exact cache** â†’ instant match.
   * **Semantic cache** â†’ similarity match above threshold.

---

## ğŸ”„ Example Flow

1. Admin â†’ Upload `manual.pdf`.
2. Chat â†’ Ask: *â€œWhat are the safety procedures?â€*
3. Bot retrieves relevant chunks and responds with citations.
4. Repeat same query â†’ instant cached response.

---

ğŸ‘‰ Project Repository: [github.com/hajasaheer/team-chatbot](https://github.com/hajasaheer/team-chatbot)

---

